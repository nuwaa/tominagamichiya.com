# 「攻撃用AI」とは？  
――生成AIとの違いと、いま何が起きているのか

## 1. そもそも「AI」「生成AI」って何？

### AI（人工知能）
- たくさんのデータを学習して、
- パターンを見つけたり、予測したり、
- 人間の「考える」「判断する」を一部まねるコンピューターの仕組み

のことです。

### 生成AI（ジェネレーティブAI）
最近ニュースでよく聞く「生成AI」は、**新しい文章・画像・音声・動画などを作り出すAI**のことです。  
ChatGPT や 画像生成AI などがその代表例です。:contentReference[oaicite:0]{index=0}  

- 「文章を要約して」「イラストを描いて」
- 「この文章をやさしい言葉にして」

といったお願いに応えて、新しいコンテンツを作ってくれます。

---

## 2. 「攻撃用AI」ってなに？

ここで言う「攻撃用AI」とは、

> **サイバー攻撃や詐欺など、悪い目的のために使われるAI**

のことです。

AIそのものが「悪」なのではなく、

- もともと便利な生成AIを
  - 「悪い使い方」で使う
  - または「悪用専用」に作り直す

ことで **攻撃の道具になってしまったAI** を指しています。  
ヨーロッパ議会も、AIとサイバーセキュリティの関係を  
1. AIを守るためのセキュリティ  
2. AIで守るセキュリティ  
3. AIを悪用する攻撃  
という3つの次元で整理していて、③がまさに「攻撃用AI」です。:contentReference[oaicite:1]{index=1}  

---

## 3. 生成AIとの違いは？

### 共通点
- どちらも **中身の「エンジン」はほぼ同じタイプのAI**（大規模言語モデルなど）
- 人間の言葉を理解して、文章やコードなどを生成する

### 大きな違いは「ルール」と「目的」

#### 通常の生成AI（ChatGPTなど）
- 爆弾の作り方や犯罪のやり方など、**危険な内容は答えないように制限**（ガードレール）がある
- プライバシーや差別に配慮するように設計されている
- 利用規約で、犯罪目的の利用を禁止

#### 攻撃用AI・悪性LLM
- **最初からガードレールがない、または意図的に外している**
- サイバー犯罪者にとって便利なように設計されている
- ダークウェブなど、普通の検索では出てこない場所で売買されていることが多い:contentReference[oaicite:2]{index=2}  

たとえると…

> - 通常の生成AI：  
>   「危ないことはしない」ように安全装置がついた電動工具  
> - 攻撃用AI：  
>   安全装置を全部取っ払って、犯罪者向けに改造した工具  

というイメージです。

---

## 4. 実際に名前が出ている「攻撃用AI」の例

ここでは、「こんな名前が報告されている」という**事実紹介**だけをします。  
※使い方や入手方法は、安全上いっさい説明しません。

### 4-1. WormGPT（ワームジーピーティー）
- ChatGPT 風のインターフェースを持つ **悪用専用の言語モデル** として、2023年ごろからダークウェブで話題になりました。:contentReference[oaicite:3]{index=3}  
- 特徴とされる点（報告ベース）  
  - フィッシングメール（偽メール）を大量に生成  
  - ビジネスメール詐欺用の文章作成を支援  
  - マルウェア（悪意あるプログラム）コードの作成を手伝う:contentReference[oaicite:4]{index=4}  

### 4-2. FraudGPT（フロードジーピーティー）
- 名前のとおり **詐欺（Fraud）** 向けのLLMとして紹介されているツール。:contentReference[oaicite:5]{index=5}  
- 報告されている機能
  - フィッシングサイトの文章作成
  - 詐欺メッセージ・SNS投稿の文章作成
  - マルウェアや不正スクリプト生成の支援

### 4-3. DarkBERT など「ダークAI」系
- ダークウェブ上のテキストを学習したとされる **DarkBERT** など、  
  サイバー犯罪向けにチューニングしたモデル群も報告されています。:contentReference[oaicite:6]{index=6}  

### 4-4. KawaiiGPT・WormGPT 4 など新しい悪性LLM
- 2025年には、セキュリティ企業が **WormGPT 4** と **KawaiiGPT** という  
  「悪意あるLLM（ダークLLM）」を分析したレポートを公開しています。:contentReference[oaicite:7]{index=7}  
- 特徴とされる点
  - 非常にもっともらしいフィッシングメールを自動生成
  - ソーシャルエンジニアリング（人を騙す手口）用の文章を量産
  - マルウェアのひな形となるコードを作れる

※これらのツール名はあくまで「こんなものがあると報告されている」というレベルでとらえてください。  
**実際に触れたり試したりすることは、絶対にやめてください。**

---

## 5. 攻撃用AIが「できてしまうこと」

技術的にはもっといろいろありますが、**一般の生活に関係しそうなもの**に絞って説明します。

### 5-1. フィッシングメール・詐欺SMSの大量生成
- 日本語が自然で、敬語もきちんとしている
- 宛名や会社名、過去のやり取りを取り入れて**「本物そっくり」に見せる**
- 1通ずつではなく、**何万通も一気に作れる**

その結果、
- 「日本語が変だから怪しい」という判断が通用しにくくなっています。:contentReference[oaicite:8]{index=8}  

### 5-2. マルウェア・攻撃コードの作成支援
- 攻撃用AIは、プログラムを書けない人にも
  - 「ここを攻撃したい」
  - 「こういう動きのプログラムが欲しい」
 という指示だけで、**ひな形コードを作ってしまう**と報告されています。:contentReference[oaicite:9]{index=9}  

ただし現時点の研究では、

> 完全に新しいタイプのマルウェアが爆発的に増えた、というより  
> **既存の攻撃を「簡単・大量」にする道具**

という見方が強いとされています。:contentReference[oaicite:10]{index=10}  

### 5-3. 個人情報を集めて「説得力のあるだまし方」を考える
- SNSや公開情報をもとに、  
  「この人はどんな趣味・家族構成・仕事か」をある程度推測
- その上で
  - 「この人なら、こういう言い回しでお金の話を出せば引っかかりやすい」
  - 「このタイミングでこのニュースを絡めれば信用しやすい」
  といった**心理的に刺さるシナリオ**をAIが提案する、という懸念も出てきています。:contentReference[oaicite:11]{index=11}  

### 5-4. ディープフェイク・音声合成と組み合わせた詐欺
- AIで作った「ニセ動画」「ニセ音声」と、
- 攻撃用AIが作る「もっともらしい台本・メール」

を組み合わせることで、

> 「社長の声で電話が来たので、言われたとおり振り込んでしまった」

といった被害の**難易度が下がる**ことが心配されています。:contentReference[oaicite:12]{index=12}  

---

## 6. 守る側も「防御用AI」を使っている

「攻撃用AI」の話だけをすると怖くなりますが、  
**守る側もAIをどんどん活用し始めています。**

### 6-1. 不審な通信・動きを自動で見つける
- 大量のログ（出入りする通信の記録など）をAIで分析し、
- 「いつもと違う動き」「おかしなパターン」を自動で検知する技術が広がっています。:contentReference[oaicite:13]{index=13}  

### 6-2. インシデント対応の効率化
- 攻撃が起きたときのログをAIが整理して、
  - どこから入られたか
  - どの範囲に影響しているか
を素早くまとめることで、**人間の調査時間を大きく減らせる**との報告もあります。:contentReference[oaicite:14]{index=14}  

### 6-3. 法律・ルールも整備が進行中
- EUの「AI Act」や、イタリアのAI規制法などでは  
  **犯罪にAIを使うこと**や、  
  **人をだましたり操作したりするためのAI**に強い制限をかけようとしています。:contentReference[oaicite:15]{index=15}  

---

## 7. 私たち一人ひとりにできること

攻撃用AIの存在をゼロにするのは難しいですが、  
**被害に遭いにくくすること**はできます。

### 7-1. 「うまい話」ほど疑ってみる
- 日本語が自然でも、ロゴが本物でも、AIならいくらでも真似できます。
- 次のようなメール・SMSは特に要注意：
  - 「至急」「本日中」「アカウント停止」など、あおる言葉が多い
  - リンクをクリックさせようとする
  - 個人情報や認証コードの入力を求める

### 7-2. 「公式アプリ・公式サイト」から入り直す
- メール内のリンクは押さず、  
  自分で検索したり、ブックマークから公式サイトにアクセスする習慣をつける。

### 7-3. 2段階認証をできるだけオンに
- IDとパスワードが漏れても、
- スマホの認証やワンタイムパスワードがあれば、被害を減らせます。

### 7-4. 「AIだから安心」でも「AIだから危険」でもなく
- AIは**包丁や車と同じ「道具」**です。
  - 使い方次第で、生活を便利にも、危険にもします。
- 「AIだから全部信用」「AIだから全部嘘」ではなく、
  - 情報の出どころ
  - おかしな点はないか
を落ち着いて確認するクセが大事です。

---

## 8. まとめ

- 「攻撃用AI」は、**サイバー攻撃や詐欺のために悪用されるAI**のこと。
- 中身の技術はふつうの生成AIとほぼ同じだが、
  - **目的が「悪用」**
  - **安全装置（ガードレール）がない／弱い**
  という点が決定的に違います。
- WormGPT・FraudGPT・DarkBERT・KawaiiGPT など、  
  ダークウェブやアンダーグラウンドで使われる悪性LLMが報告されています。:contentReference[oaicite:16]{index=16}  
- これらは
  - フィッシングメールや詐欺メッセージの大量生成
  - マルウェアや攻撃コードの作成支援
  - 個人情報を使った巧妙なだまし方の設計
  などに使われており、**攻撃のハードルを下げてしまう**ことが問題です。
- 一方で、防御側もAIで
  - 大量のログから不審な動きを検知
  - 事故対応の効率化
  を進めており、**「攻撃用AI vs 防御用AI」の“いたちごっこ”**の様相を呈しています。:contentReference[oaicite:17]{index=17}  
- 私たちとしては、
  - 「うますぎる話」を一度疑う
  - 公式サイトやアプリから入り直す
  - 2段階認証を使う
など、基本的な対策をしっかり行うことが何より大切です。

---
