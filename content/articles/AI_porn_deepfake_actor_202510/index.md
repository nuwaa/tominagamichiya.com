---
title: "生成AIで実在俳優に似せたわいせつ画像　男性逮捕（2025年10月）"
date: 2025-11-18T18:00:00+09:00
categories: ["偽情報-AIとメディアリテラシー"]
tags: ["生成AI", "犯罪"]
---

## 1. 状況（なにが起きたのか）

- 2025年10月、警察は**生成AI（画像を自動で作るAI）**を使って  
  実在する女性俳優にそっくりなわいせつ画像を作り、  
  インターネット上で売った疑いで、男性を逮捕しました。  
- 男性は秋田市に住む会社員で、警視庁が捜査しています。  
- パソコンからは、**200人を超える芸能人に似せた性的な画像**が見つかったと報じられ、  
  実在する有名人を狙った「AIポルノ」の事件としては**全国でも初めての本格摘発**とみられています。  

警察は、  
「わいせつ電磁的記録媒体陳列」という、  
**わいせつな画像や動画をネットに公開した人を処罰する罪**にあたると見て捜査しています。

---

## 2. 原因（なぜこんなことが起きたのか）

### (1) 技術が簡単になりすぎた

- 以前は、顔を合成するには専門的なソフトと技術が必要でした。
- 今は、**無料〜安価な生成AIサービス**に  
  「この俳優に似せて」「肌の露出を増やして」などと命令文（プロンプト）を書くと、  
  **誰でもそれらしい画像を作れてしまいます。**

### (2) 「バレないだろう」という甘い考え

- 「本物じゃないから大丈夫」「顔だけ似ているだけだからセーフ」と
  勘違いしている人がいます。
- しかし、**見る側は本物だと思う可能性が高く、本人の名誉や仕事に大きなダメージ**を与えます。
- ネット上には「AIコラ」「ディープフェイクは遊び」という空気もあり、  
  罪悪感が薄くなりやすいのも問題です。

### (3) 法律とルールが追いついていない

- 日本には、ディープフェイクポルノそのものを直接取り締まる**専用の法律はまだありません**。
- 現状では  
  - わいせつ物頒布・陳列  
  - 名誉毀損  
  - 著作権侵害  
  など、**既存の法律を「つぎはぎ」で当てはめている**状況です。
- どこからが犯罪なのか、線引きが分かりづらいことも、  
  「やっても大丈夫だろう」という油断を生んでいます。

---

## 3. 問題定義（何が問題なのか）

### (1) 本人の同意のない「性被害」である

- 顔はその人の**人格そのもの**です。
- 本人の許可なく、体を合成してわいせつ画像を作ることは、  
  **心の中に踏み込む性暴力・プライバシー侵害**と言えます。
- 「直接触っていないからいい」という問題ではありません。

### (2) 一度ネットに出ると「一生消せない」可能性

- 画像が一度拡散されると、  
  - スクリーンショット  
  - 再投稿  
  - 海外サイトへの転載  
  などで、**完全に消すことはほぼ不可能**です。
- 俳優・芸能人の場合は、  
  - イメージダウン  
  - 仕事のキャンセル  
  - 家族や友人への心のダメージ  
  など、**人生全体に影響**します。

### (3) 「これは本物か？」と疑わないといけない社会に

- AIによる偽画像・偽動画が増えると、  
  **私たちはすべての画像や動画を疑いながら見る社会**になってしまいます。
- 本当に被害を受けた人の証拠動画ですら、  
  「どうせAIで作ったんでしょ」と信じてもらえない危険もあります。

---

## 4. 予測（今後どうなるか）

### (1) 取り締まりは今後も強化される

- 2025年4月には、生成AIを使ってわいせつ画像を作成・販売したとして  
  4人が逮捕された事件もあり、**警察はすでに警戒を強めていました**。  
- 今回のように「実在の芸能人を模したAIポルノ」の摘発が進むことで、  
  - 同様の行為に対する抑止力  
  - AIポルノは立派な犯罪だという社会的メッセージ  
  が強まるとみられます。

### (2) 法整備に向けた議論が加速

- 生成AIによるディープフェイクポルノの被害をテーマにした報道や  
  ポッドキャスト番組も増え、**専門家が法整備の必要性を繰り返し指摘**しています。  
- 海外では、性的ディープフェイクを**新たな性犯罪として明確に禁止する国も登場**しており、  
  日本でも  
  - 専用の新しい犯罪類型をつくるか  
  - 既存の性犯罪・名誉毀損の規定を見直すか  
  などの議論が進むとみられます。

### (3) プラットフォーム・AI企業へのプレッシャー増大

- SNSや画像共有サイト、AIサービス提供企業には、  
  - わいせつAI画像の検出・削除  
  - 有名人の顔を使った画像生成の制限  
  - 利用規約の明確化  
  など、**より強い対応が求められる**でしょう。
- 対応が甘い企業は、  
  - 信用低下  
  - 広告主の離脱  
  - 法的リスク  
  に直面する可能性があります。

---

## 5. 対策（会社として・私たちとして）

### 5-1. 会社としてできること

#### (A) 一般企業（AI企業以外）

1. **就業規則・コンプライアンスの明文化**
   - 「生成AIを使ったわいせつ画像・誹謗中傷画像の作成・拡散は禁止」  
     と明確に書き、懲戒対象であることも示す。
2. **社員研修でケーススタディ**
   - 「AIだからセーフ」という誤解を解き、  
     今回のような事件が**会社の信用にも波及する**ことを説明する。
3. **従業員が被害者になった場合の対応フロー**
   - 社内の相談窓口
   - 弁護士・専門団体との連携
   - 必要に応じた警察への相談  
   など、「誰が、何を、どこに相談するのか」を決めておく。

#### (B) SNS・生成AIサービスを提供する企業

1. **技術的フィルタリング**
   - わいせつ画像の自動検出
   - 有名人の顔に似せた画像生成を制限する機能 など。
2. **通報・削除の仕組み強化**
   - 被害者や第三者が簡単に通報できるフォームを設置し、  
     迅速に削除・アカウント停止などを行う。
3. **利用規約での明確な禁止**
   - 「実在の人物の同意のない性的画像・動画の生成・投稿を禁止」と明記し、  
     違反時のペナルティも具体的に示す。

---

### 5-2. 私たち一人ひとりができること

1. **「面白半分で作らない・見ない・拡散しない」**
   - 「AIが勝手に作った」「本人じゃないからいい」ではなく、  
     **本人への性被害として考える**。
2. **怪しい画像を見ても「絶対に共有しない」**
   - 友人に回したり、SNSでネタにしたりすると、  
     自分も加害側になってしまいます。
3. **自分や知人らしき画像を見つけたら**
   - むやみに保存・共有せず、  
     - サイトの通報機能  
     - 警察  
     - 性暴力被害のワンストップ支援センター  
     など、信頼できる相談先に助けを求める。
4. **子どもと一緒に話し合う**
   - 「自分や友だちの顔を勝手に使ってはいけない」  
   - 「困ったら大人に相談していい」  
     ということを、家庭や学校で共有する。

---

## 6. 影響（私たち・社会にどう影響するか）

### (1) 芸能人だけでなく「一般の人」も狙われるリスク

- 今回は有名俳優がターゲットでしたが、  
  - 学校の友だち  
  - 職場の同僚  
  - 元交際相手  
  など、**一般の人を狙ったディープフェイクポルノ**も国内外で報告されています。
- 誰もがスマホで写真を撮り、SNSに顔を出す時代なので、  
  **「いつ自分が狙われてもおかしくない」**とも言えます。

### (2) 画像・動画への信頼低下

- 政治・災害・事件の映像でも、  
  「これ、本物？ AIじゃないの？」と疑う必要が出てきます。
- 本当に起きた被害の映像まで「フェイク扱い」されると、  
  社会全体で**事実認識をそろえることが難しくなる**おそれがあります。

### (3) 生成AI全体への不信感

- 本来、生成AIは  
  - クリエイティブ制作  
  - ビジネスの効率化  
  - 教育・医療のサポート  
  などに役立つ技術です。
- しかし、わいせつ画像やフェイクニュースなどに悪用される事例が増えると、  
  「生成AI＝危ないもの」というイメージが強まり、  
  **本来の良い活用まで止まってしまうリスク**があります。

---

## 7. 株価への影響

- 今回の事件そのものが、  
  **特定の企業の株価を大きく動かしたという報道は、現時点では目立っていません。**
- ただし、より広い意味では、
  - 生成AIが原因の偽ニュース  
  - フェイク画像  
  が企業の評判を落とし、**株価を急落させた海外事例**も報告されています。
- そのため、投資家は
  - AIを提供する企業がどれだけ安全対策をしているか  
  - プラットフォーム運営企業が違法コンテンツにどう対処しているか  
  を、今後ますますチェックするようになると考えられます。

---

## 8. 今後の見通し（回復までの時間）

ここでいう「回復」とは、  
- 被害者が安心して生活できるようになること  
- 社会が画像・動画に対して一定の信頼を取り戻すこと  
- 生成AIを安心して使える環境が整うこと  
を指します。

### (1) 短期（数年レベル）

- まずは  
  - 警察による摘発強化  
  - SNS・AI企業の利用規約の見直し  
  - 学校や企業でのリテラシー教育  
  が進むとみられます。
- これにより、「AIポルノは犯罪」という認識は  
  数年のうちにかなり広がる可能性があります。

### (2) 中長期（数年以上）

- 法改正や新しい法律の制定には時間がかかります。
- さらに、  
  - 技術的な検出技術の進化  
  - 教育カリキュラムへの組み込み  
  - 国際的なルールづくり  
  などが進んで初めて、**「安心してAIを使える社会」**に近づきます。
- そのため、**完全な意味での信頼回復には、中長期的な取り組みが必要**だと考えられます。

---

## 9. 同様の事例との比較

### (1) 2025年4月の「日本初のわいせつAI画像事件」

- 2025年4月には、生成AIを使いわいせつ画像を販売したとして、  
  4人が逮捕された事件が報じられました。
- この事件も、**「AIを使っていればOKではない」**というメッセージを  
  社会に投げかけた点で重要です。

### (2) 未成年による同級生の画像の悪用

- 2025年には、  
  中学・高校生が同級生の写真をもとに生成AIでわいせつ動画を作り、  
  書類送検された事案も報じられています。
- 共通する問題点は、  
  - 「遊び半分」  
  - 「身近な人だからバレないと思った」  
  という軽い気持ちから始まりながら、  
  **被害者の心や将来に深刻な傷を残す**ことです。

### (3) 性的以外のディープフェイクとの違い

- 政治家や有名人の発言をねつ造した偽動画など、  
  性的ではないディープフェイクも問題になっています。
- 共通点：  
  - AIを使って「本物そっくり」に見せかける  
  - 見る人をだまして社会に混乱を起こす  
- 違う点：  
  - 性的ディープフェイクは、**個人の尊厳と性の自己決定権を直接踏みにじる**  
  - 被害者が「一生つきまとう恥」と感じやすく、  
    心理的ダメージが非常に大きい

---

## 10. まとめ

1. **「AIだからセーフ」は大きな誤解**
   - 生成AIで作ったものであっても、  
     実在の俳優や一般の人に似せたわいせつ画像を作って公開すれば、  
     立派な犯罪になり得ます。

2. **これは新しい形の「性犯罪」であり、深刻な人権侵害**
   - 直接身体に触れていなくても、  
     心や人生を傷つける性暴力だという認識が必要です。

3. **社会全体で「作らない・見ない・拡散しない」文化をつくる**
   - 法律・技術・教育の三つを組み合わせて対策を進めると同時に、  
     私たち一人ひとりが  
     - 面白半分で関わらない  
     - 被害者を笑い者にしない  
     - 困っている人がいたら支える  
     という態度を持つことが重要です。

生成AIは、本来とても便利で楽しい道具です。  
だからこそ、「人を傷つける使い方」はしない・させない。  
そのためのルールづくりとリテラシーが、これからの大きな課題です。
