<!doctype html><html lang=ja><head><meta charset=utf-8><title>生成AIで実在俳優に似せたわいせつ画像　男性逮捕（2025年10月） | 富永道也｜ITジャーナリスト</title><meta name=description content="1. 状況（なにが起きたのか） 2025年10月、警察は**生成AI（画像を自動で作るAI）**を使って
実在する女性俳優にそっくりなわいせつ画像を作り、
インターネット上で売った疑いで、男性を逮捕しました。 男性は秋田市に住む会社員で、警視庁が捜査しています。 パソコンからは、200人を超える芸能 …"><link rel=canonical href=https://tominagamichiya.com/articles/ai_porn_deepfake_actor_202510/><meta property="og:title" content="生成AIで実在俳優に似せたわいせつ画像　男性逮捕（2025年10月）"><meta property="og:description" content="1. 状況（なにが起きたのか） 2025年10月、警察は**生成AI（画像を自動で作るAI）**を使って
実在する女性俳優にそっくりなわいせつ画像を作り、
インターネット上で売った疑いで、男性を逮捕しました。 男性は秋田市に住む会社員で、警視庁が捜査しています。 パソコンからは、200人を超える芸能 …"><meta property="og:url" content="https://tominagamichiya.com/articles/ai_porn_deepfake_actor_202510/"><meta property="og:type" content="article"><meta property="og:image" content="https://tominagamichiya.com/images/ogp-default.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:site content="@tominagamichiya"><link rel=alternate type=application/rss+xml title=富永道也｜ITジャーナリスト href=https://tominagamichiya.com/index.xml><script type=application/ld+json>{"@context":"https://schema.org","@type":"NewsArticle","headline":"\"生成AIで実在俳優に似せたわいせつ画像　男性逮捕（2025年10月）\"","datePublished":"2025-11-18T18:00:00\u002b09:00","dateModified":"2025-11-18T18:00:00\u002b09:00","author":{"@type":"Person","name":"\"富永道也\""},"publisher":{"@type":"Organization","name":"\"永富華\"","logo":{"@type":"ImageObject","url":"\"https://tominagamichiya.com/images/logo.png\""}},"mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/tominagamichiya.com\/articles\/ai_porn_deepfake_actor_202510\/"},"image":"\"https://tominagamichiya.com/\""}</script><link rel=stylesheet href=/css/custom.css><script async src="https://www.googletagmanager.com/gtag/js?id=G-7HDXZ9FNLC"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-7HDXZ9FNLC",{anonymize_ip:!0})</script></head><body><header><a href=/>tominagamichiya.com</a></header><main><article class=post><h1>生成AIで実在俳優に似せたわいせつ画像　男性逮捕（2025年10月）</h1><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Home","item":"https:\/\/tominagamichiya.com\/"},{"@type":"ListItem","position":2,"name":"\"Articles\"","item":"https:\/\/tominagamichiya.com\/articles\/"},{"@type":"ListItem","position":3,"name":"\"生成AIで実在俳優に似せたわいせつ画像　男性逮捕（2025年10月）\"","item":"https:\/\/tominagamichiya.com\/articles\/ai_porn_deepfake_actor_202510\/"}]}</script><nav aria-label=breadcrumb class=breadcrumbs><a href=https://tominagamichiya.com/>Home</a>
› <a href=/articles/>Articles</a>
› <span>生成AIで実在俳優に似せたわいせつ画像　男性逮捕（2025年10月）</span></nav><br>公開日：2025-11-18　更新日：2025-11-18<div class=post-body><h2 id=1-状況なにが起きたのか>1. 状況（なにが起きたのか）</h2><ul><li>2025年10月、警察は**生成AI（画像を自動で作るAI）**を使って<br>実在する女性俳優にそっくりなわいせつ画像を作り、<br>インターネット上で売った疑いで、男性を逮捕しました。</li><li>男性は秋田市に住む会社員で、警視庁が捜査しています。</li><li>パソコンからは、<strong>200人を超える芸能人に似せた性的な画像</strong>が見つかったと報じられ、<br>実在する有名人を狙った「AIポルノ」の事件としては<strong>全国でも初めての本格摘発</strong>とみられています。</li></ul><p>警察は、<br>「わいせつ電磁的記録媒体陳列」という、<br><strong>わいせつな画像や動画をネットに公開した人を処罰する罪</strong>にあたると見て捜査しています。</p><hr><h2 id=2-原因なぜこんなことが起きたのか>2. 原因（なぜこんなことが起きたのか）</h2><h3 id=1-技術が簡単になりすぎた>(1) 技術が簡単になりすぎた</h3><ul><li>以前は、顔を合成するには専門的なソフトと技術が必要でした。</li><li>今は、<strong>無料〜安価な生成AIサービス</strong>に<br>「この俳優に似せて」「肌の露出を増やして」などと命令文（プロンプト）を書くと、<br><strong>誰でもそれらしい画像を作れてしまいます。</strong></li></ul><h3 id=2-バレないだろうという甘い考え>(2) 「バレないだろう」という甘い考え</h3><ul><li>「本物じゃないから大丈夫」「顔だけ似ているだけだからセーフ」と
勘違いしている人がいます。</li><li>しかし、<strong>見る側は本物だと思う可能性が高く、本人の名誉や仕事に大きなダメージ</strong>を与えます。</li><li>ネット上には「AIコラ」「ディープフェイクは遊び」という空気もあり、<br>罪悪感が薄くなりやすいのも問題です。</li></ul><h3 id=3-法律とルールが追いついていない>(3) 法律とルールが追いついていない</h3><ul><li>日本には、ディープフェイクポルノそのものを直接取り締まる<strong>専用の法律はまだありません</strong>。</li><li>現状では<ul><li>わいせつ物頒布・陳列</li><li>名誉毀損</li><li>著作権侵害<br>など、<strong>既存の法律を「つぎはぎ」で当てはめている</strong>状況です。</li></ul></li><li>どこからが犯罪なのか、線引きが分かりづらいことも、<br>「やっても大丈夫だろう」という油断を生んでいます。</li></ul><hr><h2 id=3-問題定義何が問題なのか>3. 問題定義（何が問題なのか）</h2><h3 id=1-本人の同意のない性被害である>(1) 本人の同意のない「性被害」である</h3><ul><li>顔はその人の<strong>人格そのもの</strong>です。</li><li>本人の許可なく、体を合成してわいせつ画像を作ることは、<br><strong>心の中に踏み込む性暴力・プライバシー侵害</strong>と言えます。</li><li>「直接触っていないからいい」という問題ではありません。</li></ul><h3 id=2-一度ネットに出ると一生消せない可能性>(2) 一度ネットに出ると「一生消せない」可能性</h3><ul><li>画像が一度拡散されると、<ul><li>スクリーンショット</li><li>再投稿</li><li>海外サイトへの転載<br>などで、<strong>完全に消すことはほぼ不可能</strong>です。</li></ul></li><li>俳優・芸能人の場合は、<ul><li>イメージダウン</li><li>仕事のキャンセル</li><li>家族や友人への心のダメージ<br>など、<strong>人生全体に影響</strong>します。</li></ul></li></ul><h3 id=3-これは本物かと疑わないといけない社会に>(3) 「これは本物か？」と疑わないといけない社会に</h3><ul><li>AIによる偽画像・偽動画が増えると、<br><strong>私たちはすべての画像や動画を疑いながら見る社会</strong>になってしまいます。</li><li>本当に被害を受けた人の証拠動画ですら、<br>「どうせAIで作ったんでしょ」と信じてもらえない危険もあります。</li></ul><hr><h2 id=4-予測今後どうなるか>4. 予測（今後どうなるか）</h2><h3 id=1-取り締まりは今後も強化される>(1) 取り締まりは今後も強化される</h3><ul><li>2025年4月には、生成AIを使ってわいせつ画像を作成・販売したとして<br>4人が逮捕された事件もあり、<strong>警察はすでに警戒を強めていました</strong>。</li><li>今回のように「実在の芸能人を模したAIポルノ」の摘発が進むことで、<ul><li>同様の行為に対する抑止力</li><li>AIポルノは立派な犯罪だという社会的メッセージ<br>が強まるとみられます。</li></ul></li></ul><h3 id=2-法整備に向けた議論が加速>(2) 法整備に向けた議論が加速</h3><ul><li>生成AIによるディープフェイクポルノの被害をテーマにした報道や<br>ポッドキャスト番組も増え、<strong>専門家が法整備の必要性を繰り返し指摘</strong>しています。</li><li>海外では、性的ディープフェイクを<strong>新たな性犯罪として明確に禁止する国も登場</strong>しており、<br>日本でも<ul><li>専用の新しい犯罪類型をつくるか</li><li>既存の性犯罪・名誉毀損の規定を見直すか<br>などの議論が進むとみられます。</li></ul></li></ul><h3 id=3-プラットフォームai企業へのプレッシャー増大>(3) プラットフォーム・AI企業へのプレッシャー増大</h3><ul><li>SNSや画像共有サイト、AIサービス提供企業には、<ul><li>わいせつAI画像の検出・削除</li><li>有名人の顔を使った画像生成の制限</li><li>利用規約の明確化<br>など、<strong>より強い対応が求められる</strong>でしょう。</li></ul></li><li>対応が甘い企業は、<ul><li>信用低下</li><li>広告主の離脱</li><li>法的リスク<br>に直面する可能性があります。</li></ul></li></ul><hr><h2 id=5-対策会社として私たちとして>5. 対策（会社として・私たちとして）</h2><h3 id=5-1-会社としてできること>5-1. 会社としてできること</h3><h4 id=a-一般企業ai企業以外>(A) 一般企業（AI企業以外）</h4><ol><li><strong>就業規則・コンプライアンスの明文化</strong><ul><li>「生成AIを使ったわいせつ画像・誹謗中傷画像の作成・拡散は禁止」<br>と明確に書き、懲戒対象であることも示す。</li></ul></li><li><strong>社員研修でケーススタディ</strong><ul><li>「AIだからセーフ」という誤解を解き、<br>今回のような事件が<strong>会社の信用にも波及する</strong>ことを説明する。</li></ul></li><li><strong>従業員が被害者になった場合の対応フロー</strong><ul><li>社内の相談窓口</li><li>弁護士・専門団体との連携</li><li>必要に応じた警察への相談<br>など、「誰が、何を、どこに相談するのか」を決めておく。</li></ul></li></ol><h4 id=b-sns生成aiサービスを提供する企業>(B) SNS・生成AIサービスを提供する企業</h4><ol><li><strong>技術的フィルタリング</strong><ul><li>わいせつ画像の自動検出</li><li>有名人の顔に似せた画像生成を制限する機能 など。</li></ul></li><li><strong>通報・削除の仕組み強化</strong><ul><li>被害者や第三者が簡単に通報できるフォームを設置し、<br>迅速に削除・アカウント停止などを行う。</li></ul></li><li><strong>利用規約での明確な禁止</strong><ul><li>「実在の人物の同意のない性的画像・動画の生成・投稿を禁止」と明記し、<br>違反時のペナルティも具体的に示す。</li></ul></li></ol><hr><h3 id=5-2-私たち一人ひとりができること>5-2. 私たち一人ひとりができること</h3><ol><li><strong>「面白半分で作らない・見ない・拡散しない」</strong><ul><li>「AIが勝手に作った」「本人じゃないからいい」ではなく、<br><strong>本人への性被害として考える</strong>。</li></ul></li><li><strong>怪しい画像を見ても「絶対に共有しない」</strong><ul><li>友人に回したり、SNSでネタにしたりすると、<br>自分も加害側になってしまいます。</li></ul></li><li><strong>自分や知人らしき画像を見つけたら</strong><ul><li>むやみに保存・共有せず、<ul><li>サイトの通報機能</li><li>警察</li><li>性暴力被害のワンストップ支援センター<br>など、信頼できる相談先に助けを求める。</li></ul></li></ul></li><li><strong>子どもと一緒に話し合う</strong><ul><li>「自分や友だちの顔を勝手に使ってはいけない」</li><li>「困ったら大人に相談していい」<br>ということを、家庭や学校で共有する。</li></ul></li></ol><hr><h2 id=6-影響私たち社会にどう影響するか>6. 影響（私たち・社会にどう影響するか）</h2><h3 id=1-芸能人だけでなく一般の人も狙われるリスク>(1) 芸能人だけでなく「一般の人」も狙われるリスク</h3><ul><li>今回は有名俳優がターゲットでしたが、<ul><li>学校の友だち</li><li>職場の同僚</li><li>元交際相手<br>など、<strong>一般の人を狙ったディープフェイクポルノ</strong>も国内外で報告されています。</li></ul></li><li>誰もがスマホで写真を撮り、SNSに顔を出す時代なので、<br>**「いつ自分が狙われてもおかしくない」**とも言えます。</li></ul><h3 id=2-画像動画への信頼低下>(2) 画像・動画への信頼低下</h3><ul><li>政治・災害・事件の映像でも、<br>「これ、本物？ AIじゃないの？」と疑う必要が出てきます。</li><li>本当に起きた被害の映像まで「フェイク扱い」されると、<br>社会全体で<strong>事実認識をそろえることが難しくなる</strong>おそれがあります。</li></ul><h3 id=3-生成ai全体への不信感>(3) 生成AI全体への不信感</h3><ul><li>本来、生成AIは<ul><li>クリエイティブ制作</li><li>ビジネスの効率化</li><li>教育・医療のサポート<br>などに役立つ技術です。</li></ul></li><li>しかし、わいせつ画像やフェイクニュースなどに悪用される事例が増えると、<br>「生成AI＝危ないもの」というイメージが強まり、<br><strong>本来の良い活用まで止まってしまうリスク</strong>があります。</li></ul><hr><h2 id=7-株価への影響>7. 株価への影響</h2><ul><li>今回の事件そのものが、<br><strong>特定の企業の株価を大きく動かしたという報道は、現時点では目立っていません。</strong></li><li>ただし、より広い意味では、<ul><li>生成AIが原因の偽ニュース</li><li>フェイク画像<br>が企業の評判を落とし、<strong>株価を急落させた海外事例</strong>も報告されています。</li></ul></li><li>そのため、投資家は<ul><li>AIを提供する企業がどれだけ安全対策をしているか</li><li>プラットフォーム運営企業が違法コンテンツにどう対処しているか<br>を、今後ますますチェックするようになると考えられます。</li></ul></li></ul><hr><h2 id=8-今後の見通し回復までの時間>8. 今後の見通し（回復までの時間）</h2><p>ここでいう「回復」とは、</p><ul><li>被害者が安心して生活できるようになること</li><li>社会が画像・動画に対して一定の信頼を取り戻すこと</li><li>生成AIを安心して使える環境が整うこと<br>を指します。</li></ul><h3 id=1-短期数年レベル>(1) 短期（数年レベル）</h3><ul><li>まずは<ul><li>警察による摘発強化</li><li>SNS・AI企業の利用規約の見直し</li><li>学校や企業でのリテラシー教育<br>が進むとみられます。</li></ul></li><li>これにより、「AIポルノは犯罪」という認識は<br>数年のうちにかなり広がる可能性があります。</li></ul><h3 id=2-中長期数年以上>(2) 中長期（数年以上）</h3><ul><li>法改正や新しい法律の制定には時間がかかります。</li><li>さらに、<ul><li>技術的な検出技術の進化</li><li>教育カリキュラムへの組み込み</li><li>国際的なルールづくり<br>などが進んで初めて、**「安心してAIを使える社会」**に近づきます。</li></ul></li><li>そのため、<strong>完全な意味での信頼回復には、中長期的な取り組みが必要</strong>だと考えられます。</li></ul><hr><h2 id=9-同様の事例との比較>9. 同様の事例との比較</h2><h3 id=1-2025年4月の日本初のわいせつai画像事件>(1) 2025年4月の「日本初のわいせつAI画像事件」</h3><ul><li>2025年4月には、生成AIを使いわいせつ画像を販売したとして、<br>4人が逮捕された事件が報じられました。</li><li>この事件も、**「AIを使っていればOKではない」**というメッセージを<br>社会に投げかけた点で重要です。</li></ul><h3 id=2-未成年による同級生の画像の悪用>(2) 未成年による同級生の画像の悪用</h3><ul><li>2025年には、<br>中学・高校生が同級生の写真をもとに生成AIでわいせつ動画を作り、<br>書類送検された事案も報じられています。</li><li>共通する問題点は、<ul><li>「遊び半分」</li><li>「身近な人だからバレないと思った」<br>という軽い気持ちから始まりながら、<br><strong>被害者の心や将来に深刻な傷を残す</strong>ことです。</li></ul></li></ul><h3 id=3-性的以外のディープフェイクとの違い>(3) 性的以外のディープフェイクとの違い</h3><ul><li>政治家や有名人の発言をねつ造した偽動画など、<br>性的ではないディープフェイクも問題になっています。</li><li>共通点：<ul><li>AIを使って「本物そっくり」に見せかける</li><li>見る人をだまして社会に混乱を起こす</li></ul></li><li>違う点：<ul><li>性的ディープフェイクは、<strong>個人の尊厳と性の自己決定権を直接踏みにじる</strong></li><li>被害者が「一生つきまとう恥」と感じやすく、<br>心理的ダメージが非常に大きい</li></ul></li></ul><hr><h2 id=10-まとめ>10. まとめ</h2><ol><li><p><strong>「AIだからセーフ」は大きな誤解</strong></p><ul><li>生成AIで作ったものであっても、<br>実在の俳優や一般の人に似せたわいせつ画像を作って公開すれば、<br>立派な犯罪になり得ます。</li></ul></li><li><p><strong>これは新しい形の「性犯罪」であり、深刻な人権侵害</strong></p><ul><li>直接身体に触れていなくても、<br>心や人生を傷つける性暴力だという認識が必要です。</li></ul></li><li><p><strong>社会全体で「作らない・見ない・拡散しない」文化をつくる</strong></p><ul><li>法律・技術・教育の三つを組み合わせて対策を進めると同時に、<br>私たち一人ひとりが<ul><li>面白半分で関わらない</li><li>被害者を笑い者にしない</li><li>困っている人がいたら支える<br>という態度を持つことが重要です。</li></ul></li></ul></li></ol><p>生成AIは、本来とても便利で楽しい道具です。<br>だからこそ、「人を傷つける使い方」はしない・させない。<br>そのためのルールづくりとリテラシーが、これからの大きな課題です。</p></div><hr><section class=related><h2>関連記事</h2><ul><li><a href=/articles/pc_memory_price_explainer/>最近なぜPC用メモリが高くなっているの？</a></li><li><a href=/articles/smaho-software-competition-law/>「スマホソフトウェア競争促進法」をやさしく解説</a></li><li><a href=/articles/jimoty_dev_breach_explained/>ジモティー開発環境への不正アクセスをやさしく解説</a></li><li><a href=/articles/takaichi_misinformation/>高市総理と「偽情報」問題をやさしく解説</a></li><li><a href=/articles/surugaya_ec_breach_explained/>駿河屋ECサイト不正アクセス問題をやさしく解説</a></li></ul></section></article></main><footer class=site-footer><hr><small>&copy; 2025 富永道也｜ITジャーナリスト</small></footer></body></html>